\documentclass[finnish,twoside,censored,tkt,sw-line]{HYthesisML}


% In theses, open new chapters only at right page.
% For other types of documents, may ask "openany" in document.
\PassOptionsToClass{openright,twoside,a4paper}{report}
%\PassOptionsToClass{openany,twoside,a4paper}{report}

\usepackage{csquotes}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% REFERENCES
%% Some notes on bibliography usage and options:
%% natbib -> you can use, e.g., \citep{} or \parencite{} for (Einstein, 1905); with APA \cite -> Einstein, 1905 without ()
%% maxcitenames=2 -> only 2 author names in text citations, if more -> et al. is used
%% maxbibnames=99 as no great need to suppress the biliography list in a thesis
%% for more information see biblatex package documentation, e.g., from https://ctan.org/pkg/biblatex

%% Reference style: select one
%% for APA = Harvard style = authoryear -> (Einstein, 1905) use:
% \usepackage[style=authoryear,bibstyle=authoryear,backend=biber,natbib=true,maxnames=99,maxcitenames=2,giveninits=true,uniquename=init]{biblatex}
%% for numeric = Vancouver style -> [1] use:
\usepackage[style=numeric,bibstyle=numeric,backend=biber,natbib=true,maxbibnames=99,giveninits=true,uniquename=init]{biblatex}
%% for alpahbetic -> [Ein05] use:
%\usepackage[style=alphabetic,bibstyle=alphabetic,backend=biber,natbib=true,maxbibnames=99,giveninits=true,uniquename=init]{biblatex}
%

\addbibresource{bibliography.bib}
% in case you want the final delimiter between authors & -> (Einstein & Zweistein, 1905)
% \renewcommand{\finalnamedelim}{ \& }
% List the authors in the Bibilipgraphy as Lastname F, Familyname G,
\DeclareNameAlias{sortname}{family-given}
% remove the punctuation between author names in Bibliography
%\renewcommand{\revsdnamepunct}{ }


%% Block of definitions for fonts and packages for picture management.
%% In some systems, the figure packages may not be happy together.
%% Choose the ones you need.

%\usepackage[utf8]{inputenc} % For UTF8 support, in some systems. Use UTF8 when saving your file.

\usepackage{lmodern}         % Font package, again in some systems.
\usepackage{textcomp}        % Package for special symbols
\usepackage[pdftex]{color, graphicx} % For pdf output and jpg/png graphics
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage[pdftex, plainpages=false]{hyperref} % For hyperlinks and pdf metadata
\usepackage{fancyhdr}        % For nicer page headers
\usepackage{tikz}            % For making vector graphics (hard to learn but powerful)
%\usepackage{wrapfig}        % For nice text-wrapping figures (use at own discretion)
\usepackage{amsmath, amssymb} % For better math
\graphicspath{{../kuvat/}}

\singlespacing{}               %line spacing options; normally use single

\fussy
%\sloppy                      % sloppy and fussy commands can be used to avoid overlong text lines
% if you want to see which lines are too long or have too little stuff, comment out the following lines
% \overfullrule=1mm
% to see more info in the detailed log about under/overfull boxes...
% \showboxbreadth=50
% \showboxdepth=50



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% STEP 2:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Set up personal information for the title page and the abstract form.
%% Replace parameters with your information.
\title{Koneoppiminen lääkkeiden kehityksessä}

% TM: Contributors to template editors now listed in the beginning of the file in comments
\author{Heikki Pulli}
\date{\today}



% Set supervisors and examiners, use the titles according to the thesis language
% Prof.
% Dr. or in Finnish toht. or tri or FT, TkT, Ph.D. or in Swedish...
\supervisors{Prof.~D.U.~Mind, Dr.~O.~Why}
\examiners{Prof.~D.U.~Mind, Dr.~O.~Why}


\keywords{ulkoasu, tiivistelmä, lähdeluettelo}
\additionalinformation{\translate{\track}}

%% For seminar reports:
%%\additionalinformation{Name of the seminar}

%% Replace classification terms with the ones that match your work. ACM
%% ACM Digital library provides a taxonomy and a tool for classification
%% in computer science. Use 1-3 paths, and use right arrows between the
%% about three levels in the path; each path requires a new line.

\classification{\protect{\ \ \
\  General and reference \(\rightarrow \) Document types  \(\rightarrow \) Surveys and overviews\  \\
\  Applied computing  \(\rightarrow \) Document management and text processing  \(\rightarrow \) Document management \(\rightarrow \) Text editing
}}

%% if you want to quote someone special. You can comment this line out and there will be nothing on the document.
%\quoting{Bachelor's degrees make pretty good placemats if you get them laminated.}{Jeph Jacques}


%% OPTIONAL STEP: Set up properties and metadata for the pdf file that pdfLaTeX makes.
%% Your name, work title, and keywords are recommended.
% \hypersetup{
%     unicode=true,           % to show non-Latin characters in Acrobat’s bookmarks
%     pdftoolbar=true,        % show Acrobat’s toolbar?
%     pdfmenubar=true,        % show Acrobat’s menu?
%     pdffitwindow=false,     % window fit to page when opened
%     pdfstartview={FitH},    % fits the width of the page to the window
%     pdftitle={},            % title
%     pdfauthor={},           % author
%     pdfsubject={},          % subject of the document
%     pdfcreator={},          % creator of the document
%     pdfproducer={pdfLaTeX}, % producer of the document
%     pdfkeywords={something} {something else}, % list of keywords for
%     pdfnewwindow=true,      % links in new window
%     colorlinks=true,        % false: boxed links; true: colored links
%     linkcolor=black,        % color of internal links
%     citecolor=red,        % color of links to bibliography
%     filecolor=magenta,      % color of file links
%     urlcolor=cyan           % color of external links
% }

%%-----------------------------------------------------------------------------------

\begin{document}

% Generate title page.
\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% STEP 3:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Write your abstract to be positioned here.
%% You can make several abstract pages (if you want it in different languages),
%% but you should also then redefine some of the above parameters in the proper
%% language as well, in between the abstract definitions.

\begin{abstract}

    Tämä dokumentti on tarkoitettu Helsingin yliopiston tietojenkäsittelytieteen osaston opin\-näyt\-teiden ja harjoitustöiden ulkoasun ohjeeksi ja mallipohjaksi. Ohje soveltuu kanditutkielmiin, ohjelmistotuotantoprojekteihin, seminaareihin ja maisterintutkielmiin. Tämän ohjeen lisäksi on seurattava niitä ohjeita, jotka opastavat valitsemaan kuhunkin osioon tieteellisesti kiinnostavaa, syvällisesti pohdittua sisältöä.


    Työn aihe luokitellaan
    ACM Computing Classification System (CCS) mukaisesti,
    ks.\ \url{https://www.acm.org/about-acm/class},
    käyttäen komentoa \verb+\classification{}+.
    Käytä muutamaa termipolkua (1--3), jotka alkavat juuritermistä ja joissa polun tarkentuvat luokat erotetaan toisistaan oikealle osoittavalla nuolella.

\end{abstract}

% \begin{otherlanguage}{english}
%     \begin{abstract}
%         Use this otherlanguage environment to write your abstract in another language if needed.

%         Topics are classified according to the ACM Computing Classification System
%         (CCS), see
%         \url{https://www.acm.org/about-acm/class}:
%         check command \verb+\classification{}+. A small set of paths (1--3) should be used, starting from any top nodes
%         referred to bu the root term CCS leading to the leaf nodes. The elements
%         in the path are separated by right arrow, and emphasis of each element individually can be indicated
%         by the use of bold face for high importance or italics for intermediate
%         level. The combination of individual boldface terms may give the reader
%         additional insight.
%     \end{abstract}
% \end{otherlanguage}

% Place ToC
\newpage
\mytableofcontents{}
\mainmatter{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% STEP 4: Write the thesis.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Your actual text starts here. You shouldn't mess with the code above the line except
%% to change the parameters. Removing the abstract and ToC commands will mess up stuff.
%%
%% You may wish to include material to avoid browsing the definitions
%% above. Command \include{file} includes the file of name file.tex.
%% As a side effect, subsequent inclusions may force a page break.

% BSc instructions
%\include{bsc_finnish_contents}
%\include{bsc_english_contents}
% MSc instructions
%\include{msc_finnish_contents}
% \include{msc_english_contents}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Johdanto}

Uusien lääkkeiden kehittäminen on pitkä ja kallis prosessi.
Tähän kuuluu useita vaiheita ja eri vaiheet vievät eri määrän rahaa ja aikaa.
Vaiheet ovat sairauden aiheuttajan tunnistaminen, aiheuttajaan vaikuttavan lääkkeen tunnistaminen, lääkkeen optimointi, lääkkeen ominaisuuksien analysointi ja kliiniset testit.
Näiden vaiheiden jälkeen lääke joko hyväksytään myyntiin tai sitä joudutaan edelleen jatkokehittämään.
Kaikki vaiheet yhdessä ovat tavallisesti vieneet 10--12 vuotta ja kaikkien vaiheiden jälkeen työn hinnaksi on voinut muodostua 1--3 miljardia dollaria~\cite{EkinsSean2019Emlf}.

Vaiheiden pitkän keston ja korkean hinnan takia tutkijat ja lääkealan yritykset ovatkin alkaneet tutkia mahdollisia keinoja, jotka nopeuttaisivat lääkkeiden tutkimista tai laskisivat lääkekehityksen prosessiin kuluvaa hintaa.
Koneoppimismallit ovat nousseet houkuttelevaksi vaihtoehdoksi ratkaisemaan näitä ongelmia.
Yritykset ovatkin alkaneet selvittää, kuinka eri koneoppimismalleja voidaan hyödyntää nopeuttamaan lääketutkimuksen suurimpia pullonkauloja~\cite{EkinsSean2019Emlf}.

Viimeisen kymmenen vuoden aikana saatavilla olevan laadukkaan datan määrä on kasvanut merkittävästi ja samalla on kehitetty uusia tehokkaampia koneoppimismalleja, joita voidaan hyödyntää lääketutkimuksessa~\cite{ButlerKeithT2018Mlfm,VamathevanJessica2019Aoml}.
Koneoppimismallien avulla voidaan esimerkiksi karsia kaikista harkinnasta olevista lääkkeistä lupaavimmat kandidaatit, joilla on mahdollisuus päästä testeistä läpi tuotantoon~\cite{GayvertKaitlyn}.
Koneoppimismalleja voidaan myös hyödyntää aivan uusien lääkkeeksi sopivien yhdisteiden etsinnässä~\cite{ShinBonggun,ShaharHarelAndKiraRadinsky}.
Tähän tarkoitukseen kehitetyt koneoppimismallit kykenevät etsimään lääkkeitä, joilla on halutut lääkkeelliset ja fysikaaliset ominaisuudet~\cite{VamathevanJessica2019Aoml}.
Kehitetyt mallit ovatkin näyttäneet, että koneoppimismallit ovat tehokkaita työkaluja, joita voidaan hyödyntää kaikissa lääketutkimuksen eri vaiheissa.

Tässä tekstissä paneudutaan syvemmin koneoppimismalleihin, joita käytetään uusien lääkkeiden tunnistamiseen ja näiden tunnistettujen lääkkeiden syntetisoinnin suunnitteluun.
Tekstin tarkoituksena on tutustuttaa lukija sekä koneoppimisen käsitteistöön ja erilaisiin malleihin että ongelmiin, jotka liittyvät lääkkeiden löytämiseen ja löydettyjen lääkkeiden syntetisoinnin suunnitteluun.
Käsiteltävät koneoppimismenetelmät toimivat esimerkkeinä, kuinka koneoppimista voidaan käyttää käsiteltävissä konteksteissa.

Ensimmäisessä kappaleessa tutustutaan eri datatyyppeihin, joita käytetään koneoppimismallien kouluttamisessa.
Tämä on lyhyt kappale, jossa käydään vain ne datatyypit läpi, joita myöhemmin selitettävät koneoppimismallit käyttävät.
Näiden ymmärtäminen auttaa hahmottamaan myöhemmin tekstissä selitettävien eri mallien toimintaperiaatteita.

Toisessa kappaleessa käydään läpi, kuinka uusia lääkkeitä löydetään.
Kappaleessa kerrotaan virtualisesta seulonnasta (Virtual screening), mitä sillä tarkoitetaan ja kuinka sitä hyödynnetään.
Lisäksi toisessa kappaleessa käydään läpi yhden koneoopimismallin toimintaa, joka on koulutettu löytämään uusia yhdisteitä.
Tämä malli mahdollistaa uusien lääkkeiden löytämisen nopeasti, joita näin ollen päästään jatkotutkimaan nopeasti.

Kolmas kappale paneutuu yhdisteiden syntetisointiin ja kuinka sitä voidaan toteuttaa hyödyntämällä koneoppimismalleja.
Kappaleessa käsitellään, kuinka syntetisointia voidaan suunnitella retrosynteesianalyysin avulla, mikä tekee yhdisteiden retrosyntetisointianalyysista hankalaa ja mitä ratkaisuja tähän on kehitetty.
Kappale kertoo CASP -menetelmistä (\textbf{Computer Aided Synthesis Planning}) ja kuinka täma liittyy retrosyntetisointianalyysiin.
Lisäksi kappaleessa käydään läpi kahden eri koneoppimismallin toimintaa, jotka on kehitetty auttamaan eri yhdisteiden syntetisoinnin suunnittelussa.

Neljäs kappale käsittelee, kuinka koneoppimista tullaan käyttämään tulevaisuuden lääkekehityksessä ja tutkimisessa.
Kappale kertoo, kuinka koneoppiminen tulee enenemissä määrin muuttamaan lääkekehityksen prosessia.

\chapter{Kemiallinen data}

Tässä kappaleessa käydään pintapuolisesti läpi, minkälaista dataa käytetään mallien kouluttamiseen.
Kappaleessa keskitytään datatyyppeihin, joita käytetään malleissa, joiden toimintaa tullaan avaamaan tämän tekstin muissa osissa.
Mallit, joiden toimintaa avataan, käyttävät datatyyppejä, joilla kuvataan pienyhdisteitä.
Tämän takia kappaleessa keskitytään vain pieniäyhdisteitä kuvaaviin datatyyppeihin.
Kappaleessa käydään läpi SMILES ja SMARTS datatyypit, mihin niitä käytetään ja kuinka ne eroavat toisistaan.
Kappaleessa myös kerrotaan, mitä ovat yhdisteiden ECFP -tunnisteet ja mitä ovat ominaisuusvektoreista ja mitä tietoa ne sisältävät yhdisteistä.

\section{Yhdisteiden kuvaaminen merkkijonoilla}

\begin{figure}[!h]
    \centering
    \includegraphics[width=8cm, height=8cm]{melatonin-smiles.png}
    \caption{Melatoniini yhdiste, kuinka se kuvataan graaffina ja SMILES -merkijonona.
        Kuva on tuotettu hyödyntämällä RDKit -kirjastoa.}
    \label{fig:melatonin}
\end{figure}

Tavallinen tapa kuvata yhdisteitä on kuvata ne yhdellä rivillä merkkijonoina.
SMILES (Simplified Molecular Input Line Entry System) on David Weiningerin vuonna 1988 kehittämä tapa kuvata molekyylejä ja yksinkertaisia yhdisteitä~\cite{WeiningerSMILES}.
Se kuvaa yhdisteen yhdellä rivillä käyttäen ASCII -merkistöä.
Kuvassa~\ref{fig:melatonin} on esitetty melatoniini yhdiste ja kuinka se kuvataan SMILES muodossa.
Tämän takia se on tietokoneen nopea lukea ja kemistin helppo ymmärtää.

SMARTS (SMILES arbitrary target specification) on SMILES -standardista jatkokehitetty tapa kuvata yhdisteitä.
Se mahdollistaa yhdisteiden sisäisten rakenteiden määrittämisen.
SMARTS on yläluokka SMILES standardista, jonka takia kaikki SMILES -merkkijonoiksi kelpaavat merkkijonot ovat myös kelpoja SMARTS -merkkijonoja.
SMARTS ja SMILES standardit mahdollistavat myös kemiallisten reaktioiden kuvaamisen ASCII -merkistöllä yhdellä rivillä.

\section{Yhdisteiden kuvaaminen bitteinä, ECFP}

Toinen tavallinen tapa kuvata yhdisteitä on muuttaa ne ECFP (Extended Connectivity FingerPrint) -bitttijonoiksi~\cite{RogersDavid2010EF}.
ECFP -tunniste lasketaan käyttämällä Morganin algoritmia, joka laskee jokaiselle yhdisteen atomille numeerisen arvon käyttämällä hajautusfunktiota ja iteroimalla ja laskemalla näitä arvoja yhteen se saa laskettua yhdisteen eri osille niitä kuvaavat numeeriset arvot.
ECFP -tunnisteita kutsutaan myös Morgan -tunnisteiksi (Morgan Fingerprint).
Nämä numeeriset arvot voidaan muuttaa sitten halutun mittaisiksi bittiesityksiksi~\cite{RogersDavid2010EF}.
ECFP on yksi monista tavoista kuvata yhdisteitä numeerisessa muodossa, mutta se on yksi käytetyimmistä menetelmistä sen nopean ja helpon laskemisen takia.
Bittijonojen etuna on se, että ne vievät vähän muistia lyhyillä bittijonoilla, mutta lyhyjen bittijonojen ongelmana on, että ne saattavat menettää oleellista tietoa yhdisteestä bittitörmäysten takia.

\section{Ominaisuusvektorit}

Yksi tässä tekstissä käsiteltävistä koneoppimismalleista käyttää ominaisuusvektoreita hyödykseen.
Ominaisuusvektorit sisältävät tietoa yhdisteen tai molekyylin lääkkeellisistä ominaisuuksista.
Ominaisuusvektorit voivat kuvata mitä tahansa yhdisteen tai molekyylin ominaisuutta ja ne voidaan valita tilanteen mukaan.
Kyseisessä mallissa ominaisuusvektorit kuvaavat molekyylin PlogP, QED ja DRD2 arvoja~\cite{ShinBonggun}.
PlogP (Penalized logP) kuvaa aineen rasvaliukoisuutta, QED kuvaa tietyn yhdisteen lääkkeenkaltaisuutta ja DRD2 kuvaa, kuinka paljon molekyyli reagoi dopamiini 2 receptoria vastaan~\cite{BickertonGRichard2012Qtcb}.
Nämä ovat oleellisia tietoja tutkittaessa uusia mahdollisia lääkeyhdisteitä~\cite{ShinBonggun}.

\chapter{Uusien lääkkeiden löytäminen}

Tässä kappaleessa kerrotaan, mitä asioita liittyy lääkkeiden löytämiseen.
Lisäksi kappaleessa kerrotaan, mitä on virtuaalinen seulonta ja kuinka sitä hyödynnetään lääkkeiden etsinnässä.
Kappaleessa myös käydään läpi yhden koneoppimismallin toimintaperiaate.
Kyseinen koneoppimismalli luo uusia lääkkeitä perustuen ominaisuusvektoreihin.

\section{Lääkkeiden löytäminen}

Yksi ensimmäisistä lääkekehityksen osa-alueista on uusien lääkkeiksi kelpaavien yhdisteiden löytäminen joko uusiin tai jo tunnettuihin tauteihin~\cite{EkinsSean2019Emlf}.
Lääkeyhdisteiden löytäminen on kuitenkin ollut tavallisesti hidas prosessi ja uuden toimivan yhdisteen löytäminen on kestänyt useita vuosia~\cite{EkinsSean2019Emlf,MunosBernardH2011Htrb}.
On itse asiassa huomattu, että uusien lääkkeiden löytäminen on muuttunut yhä kalliimaksi ja uusia lääkkeitä tulee markkinoille vähemmän kuin aikaisemmin~\cite{MunosBernardH2011Htrb}.
Koneoppimista onkin alettu hyödyntämään tässä vaiheessa nopeuttamaan prosessiin kuluvaa aikaa~\cite{VamathevanJessica2019Aoml}.

Viimeisimmän kymmenen vuoden aikana saatavilla olevan datan määrä koskien lääkkeitä ja lääkeyhdisteitä on kasvannut merkittävästi kehitettyjen tietopankkien takia~\cite{EkinsSean2019Emlf}.
Näitä ovat esimerkiksi PubChem ja ChEMBL~\cite{NationalCenterForBiotechnologyInformation,chembl}.
Molemmat näistä tietopankeista keskittyvät lääkeyhdisteiden tietojen tallentamiseen.
PubChem on yhdysvaltain terveysviraston (National Institute of Health) ylläpitämä ja ChEMBL on Euroopan bioinformatiikka instituution (European Bioinformatics Institute, EBI) ylläpitämä.

% Lisääntynyt datan määrä on täten mahdollistanut lääkkeiden löytämisen nopeuttamisen koneoppimismallien avulla.

% Popovan et al.\ tutkimusryhmä on kehittänyt mallin, joka ehdottaa uutta yhdistettä perustuen mallin syötteenä saamaan ominaisuusvektoriin~\cite{PopovaMariya2018Drlf}.

\section{Virtuaalinen seulonta}

Kemiallisten yhdisteiden avaruudella tarkoitetaan kaikkien uniikkien yhdisteiden lukumäärää.
On arvioitu, että erilaisia kemiallisia yhdisteitä, jotka voivat esiintyä huoneenlämmössä nesteessä, voi olla välillä \(10^{18} - 10^{180}\)~\cite{SotrifferChristoph2011VSPC}.
Yhdisteet, jotka täyttävät lääkkeeltä vaaditut kriteerit, on puolestaan arvioitu olevan noin \(10^{60}\)~\cite{SotrifferChristoph2011VSPC}.
Erillaisten yhdisteiden suuri lukumäärä itsessään esittää tarpeen tehokkaille algoritmeille ja menetelmille, jotka auttavat karsimaan tästä suuresta määrästä kemiallisia yhdisteitä vain lupaavimmat.

Virtuaaliseulonta (Virtual Screening, VS) on suosittu lähestymistapa uusien lääkkeiden tai lääkkeeksi kelpaavien yhdisteiden löytämiseksi.
Virtuaaliseulonta käsittää joukon menetelmiä, joissa tietokoneita hyväksi käyttäen karsitaan yhdisteiden avaruudesta vain tietyt kriteerit täyttävät yhdisteet~\cite{SotrifferChristoph2011VSPC}.
Yhdisteiden karsimiseen käytetään ohjelmistoja, joissa toteutetut algoritmit suorittavat seulontaa annetuilla parametreilla.

Koneoppimismenetelmiä voidaan myös käyttää virtuaalisessa seulonnassa~\cite{SotrifferChristoph2011VSPC}.
Yleisimpiä koneoppimismenetelmiä ovat tällä hetkellä SVM (Support Vector Machine) ja Random forest -mallit~\cite{SotrifferChristoph2011VSPC}.
Neuroverkko ja ensemble -koneoopimismallit ovat myös yleistyneet viimevuosina~\cite{ShinBonggun,PopovaMariya2018Drlf}.
Ensemble -mallien ideana on yhdistää useita eri koneoppimismalleja yhdeksi malliksi~\cite{RokachLior2009Ec}.
Ensemble -mallit ovat tavallisesti parempia ja monipuolisempia toiminnalisuuksissaan kuin yksittäiset koneoppimismallit ja luovat tarkempia tuloksia.

koneoppimismallien avulla löydettyjä yhdisteitä voidaan sitten jatkotutkia ja edelleen kehittää lääkkeiksi.

\section{Kehitettyjä koneoppimismalleja}
Käydään seuraavaksi läpi erään toteutetun koneoppimismallin toimintaperiaate.
Kyseinen malli etsii uusia lääkkeitä käyttämällä hyödyksi sille annettua prototyyppiyhdistettä, prototyypin kemiallisia ominaisuuksia ja uudelta lääkkeeltä haluttuja kemiallisia ominaisuuksia.
Kemialliset ominaisuudet on koodattu ominaisuusvektoreihin.

\subsection{CMG -malli}

CMG (Controlled molecule generator) on koneoppimismalli, joka etsii uusia molekyylejä, jotka perustuvat syötteenä annettuun molekyyliin ja joilla on ennalta määritellyt halutut ominaisuudet~\cite{ShinBonggun}.
CMG -mallin toimintaperiaatteen idea on muokata prototyyppiyhdistettä siten, että se maksimoi halutut ominaisuudet, jotka on määritelty sen syötteenä saamassa ominaisuusvektorissa.
CMG -mallin toimintaa rajoittaa kuitenkin prototyyppi yhdiste ja syötteenä annettu samanlaisuusluku, jonka alle uuden luodun yhdisteen ja prototyyppi yhdisteen välinen tanimoto -indeksi ei saa mennä.
Tanimoto -indeksi kuvaa, kuinka paljon molekyylit muistuttavat toisiaan rakenteellisesti~\cite{MaggioraGerald2014Msim}.
Tanimoto -indeksin arvot ovat välillä \([0,1]\).

CMG -malli eroaa aikaisemmin kehitetyistä malleista siten, että se pystyy optimoimaan annetun molekyylin useampaa ominaisuutta samanaikaisesti.
Aikaisemmin kehitetyt mallit ovat pystyneet optimoimaan vain yhtä molekyylin ominaisuutta.

CMG -malli muodostuu kolmesta verkosta, joista kaksi toimivat rajoiteverkkoina.
Ensimmäinen verkko on MTN (\textbf{Molecule Translation Network}) ja rajoiteverkot ovat PPN (\textbf{Property Prediction Network}) ja SPN (\textbf{Similarity Prediction Network}).
Kuvassa~\ref{fig:cmg-model-whole} näkyy CMG -mallin rakenne ja toimintaperiaate.

CMG:n kehittäjät lähestyvät molekyylin ominaisuuksien optimointiongelmaa merkkijonojen käännös -ja luontiongelmana.
CMG:lle opetetaan, kuinka syötteenä annettu yhdistemerkkijono käännetään yhdistemerkkijonoksi, jolla on lähimpänä haluttuja ominaisuuksia olevat ominaisuudet.
CMG tulkitsee ensin annetut merkkijonot hyödyntäen DN:ää (deep network) jonka jälkeen se luo uusia molekyyliyhdisteitä hyödyntäen tätä tulkintaa ja haluttua ominaisuusvektoria.
Koska ominaisuudet annetaan vektorina, niin CMG pystyy optimoimaan useampaa ominaisuutta samanaikaisesti.
CMG lisäksi hyödyntää ennalta koulutettuja rajoiteverkkoja (constraint network, CN), jolloin vältytään luomasta mahdottomia yhdisteitä.
CMG -malli käyttää näitä verkkoja hyödyksi käyttämällä muokattua Beam Search -algoritmia.

Beam Searh -algoritmi saa syötteenä kaikki CMG -mallin kehittämät yhdisteet, pisteyttää ne ja palauttaa yhdisteen, joka sai parhaimman pisteytyksen.
Algoritmi käyttää PPN -verkkoa ennustaessaan kehitetyn molekyylin ominaisuuksia ja SPN -verkkoa laskiessaan, kuinka samankaltainen kehitetty yhdiste on CMG -mallin syötteenä saadun yhdisteen kanssa.
Näiden tietojen avulla algoritmi laskee kehitetyille yhdisteille numeeriset arvot ja palauttaa yhdisteen, joka saa parahaimman arvon.

Data, jolla mallit koulutetaan, on peräisin ZINC -tietokannasta ja DRD2 dataseteistä.
ZINC on ilmainen tietokanta, joka sisältää tietoa lääkeyhdsteistä, ja jota voidaan käyttää virtuaalisessa seulonnassa~\cite{ZINC}.
ZINC tietokantaa ylläpitää Irwin ja Shoichet laboratoriot Kalifornian yliopistossa.
DRD2 datasetti sisältää tietoa yhdisteistä ja kuinka nämä yhdisteet reagoivat dopamiini 2 receptorin kanssa.
DRD2 datasetti luotiin Olivecrona et al.\ tutkimuksen yhteydessä ja sitä käytetään samalla tavalla CMG -mallissa.

Data sisältää kaiken kaikkiaan 257 565 molekyyliä, joista luodaan pareja.
Parit muodostetaan siten, että kahden molekyylin välinen tanimoto -indeksi on yli 0.4.
Näitä pareja \((X,Y)\) muodostetaan kaiken kaikkiaan 10 827 615 kappaletta.
Lisäksi kaikille molekyyleille lasketaan niiden eri kemiallisten ominaisuuksien arvot, jotka ovat PlogP, QED ja DRD2.
Nämä kuvaavat eri ominaisuuksia, joita malli pyrkii optimoimaan halutulla tavalla.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{CMG-fig.png}
    \caption{CMG:n toiminta periaate kuvattuna}
    {~\cite{ShinBonggun}}
    \label{fig:cmg-model-whole}
\end{figure}

\subsubsection{MTN -verkko}

MTN -verkko perustuu aikaisemmin kehitettyyn Transformer -malliin~\cite{TheTransformer}.
Transformer -malli eroaa aikaisemmin yleisistä NLP -malleista siten, että se perustuu täysin attention -perusteiseen lähestymistapaan.
Transformer -malli noudattaa encoder-decoder arkkitehtuuria.
Encoder ensin muuntaa saamansa syötteen jokaisen sanan todennäköisyysjakaumaksi ja nämä todennäköisyysjakaumat syötetään decoder -osiolle.
Tämän todennäköisyysjakauman ja aikaisemman sanan avulla se määrittää seuraavan sanan tulosteeseen.

MTN eroaa Transformer -mallista kahdella tavalla.
Toisin kuin Transformer -malli, joka käsittelee sanoja ja niistä muodostettuja lauseita, MTN -verkko käsittelee yksittäisiä merkkejä ja niistä muodostettuja molekyylejä.
Lisäksi MTN:än piilotettuun kerrokseen on lisätty tietoa kemiallisista ominaisuuksista.

\subsubsection{PPN -verkko}

\begin{figure}[!h]
    \centering
    \includegraphics[width=10cm, height=8cm]{cmg-property-prediction-network.png}
    \caption{CMG -mallin PPN -neuroverkon rakenne}
    {~\cite{ShinBonggun}}
    \label{fig:cmg-model-ppn}
\end{figure}

PPN -verkon rakenne ja toiminta periaate näkyvät kuvassa~\ref{fig:cmg-model-ppn}.
PPN -verkko ottaa syötteenä ennustetun molekyylin merkkijonon (\(y_i\)).
Tämä merkkijono muunnetaan piilotetuiksi vektoreiksi hyödyntäen Bidirectional Long short-term memory (biLSTM) -kerrosta.
BiLSTM on rakenteeltaan samanlainen kuin LSTM taso, mutta koska se käsittelee syötteen sekä alku-loppu suunnassa että loppu-alku suunnassa se oppii tietyn merkin konteksin molemmissa suunnissa.
BiLSTM -kerros muodostaa vektoreita oikealta vasemmalle ja vasemmalta oikealle suunnassa, ja näistä vektoreista valitaan molempien suuntien viimeiset vektorit.
Nämä vektorit yhdistetään ja yhdistevektori syötetään täysin yhdistetylle neuroverkolle.
Tämä verkko sisältää kaksi piilotettua tasoa.
Verkko antaa tuloksena kyseisen yhdisteen ominaisuuksien ennusteen.

PPN koulutetaan käyttäen 257 565 eri molekyyliä.
nämä molekyylit jaetaan satunnanvaraisella valinnalla koulutus -ja testiryhmiin suhteella 8:2.

\subsubsection{SPN -verkko}

\begin{figure}[!h]
    \centering
    \includegraphics[width=10cm, height=8cm]{cmg-similarity-network.png}
    \caption{CMG -mallin SPN -neuroverkon rakenne}
    {~\cite{ShinBonggun}}
    \label{fig:cmg-model-spn}
\end{figure}

SPN verkon rakenne ja toimintaperiaate on kuvattu kuvassa~\ref{fig:cmg-model-spn}
SPN ottaa syötteenä ennustetun molekyylin merkkijonon (\(y_i\)) ja alkuperäisen molekyylin merkkijonon (\(x_i\)).
Nämä merkkijonot syötetään kahdelle eri biLSTM -tasolle, toinen käsittelee alkuperäisen molekyylin merkkijonot ja toinen ennustetun molekyylin merkkijonot.
Nämä biLSTM -kerrokset tomivat samalla periaatteella kuin PPN:ässä ja palauttavat näin ollen neljä eri vektoria, kaksi ennustetulta merkkijonolta ja kaksi alkuperäiseltä merkkijonolta.
Nämä vektorit yhdistetään ja tämä yhdistevektori annetaan täysin yhdistetylle verkolle, joka sisältää kaksi piilotettua tasoa.
Tämä verkko toimii binääriluokittelijana ja palauttaa, onko kaksi syötemolekyyliä samanlaisia määritellyn samanlaisuus rajan mukaan.

SPN kouluttamiseen käytetään osajoukkoa 10 827 615 eri parista.
Tästä määrästä valitaan kymmenen prosentin osajoukko, joka on 997 773 molekyylin suuruinen.
Tämä joukko jaetaan samalla tavalla koulutus ja testi ryhmiin kuin PPN:ässä.

\chapter{Uusien lääkkeiden syntetisointi}

Tässä kappaleessa käydään läpi, miten lääkkeiden syntetisoinnin suunnittelua voidaan tehostaa koneoppimismallien avulla.
Kappaleessa keskitytään syntetisoinnin suunnitteluun käytämällä retrosyntetisointi menetelmää.
Kappaleessa kerrotaan, mikä tekee yhdisteen retrosyntetisoinnista vaikeaa ja kuinka sitä voidaan tehostaa hyödyntämällä eri koneoppimismalleja.
Kappaleessa käydään läpi kahden koneoppimismallin toimintaa, jotka suorittavat halutun yhdisteen retrosyntetisointia.

\section{Yhdisteiden syntetisointi}

Yhdisteen syntetisoinnin suunnittelulla tarkoitetaan prosessia, jossa määritellään, kuinka haluttu yhdiste voidaan tuottaa synteettisesti saatavilla olevista lähtöaineista~\cite{ColeyConnorW2018MLiC}.
Retrosynteesianalyysillä tarkoitetaan puolestaan menetelmää, jonka avulla löydetään halutun yhdisteen tuottamiseen tarvittavat lähtöaineet.
Retrosynteesi toimii siis toiseen suuntaan kuin syntetisointi.
Retrosynteesissä yhdiste pilkotaan rekursiivisesti pienempiin lähtöaineisiin kunnes jäljellä on vain saatavilla olevia lähtöaineita~\cite{ECoreyRetrosynthesis}.

Tavallisesti yhdisteen retrosyntetisointi on vaatinut suorittavalta kemistiltä usean vuoden kokemusta ja tietoa saatavilla olevista lähtöaineista ja eri reaktioista.
Tätä on pyritty automatisoimaan eri CASP -menetelmien avulla (Computer-Aided Synthesis Planning).
CASP on jo 1960 -luvulla kehitetty idea, ja ensimmäisiä yrityksiä toteuttaa retrosyntetisointia tekoälyn avulla oli E.J Coreyn LHASA -projekti~\cite{ColeyConnorW2018MLiC}.
LHASA perustui heuristisiin algoritmeihin, joissa kemistit käsin koodasivat, miten eri lähtöaineet reagoivat keskenään ja mikä on reaktion lopputuote~\cite{LHASA}.
Tämä on kuitenkin osoittautunut toivottomaksi yritykseksi massiivisen data määrän takia.

Kehitys koneoppimismenetelmissä on kuitenkin tarjonnut uuden lähestymistavan CASP -menetelmien kehitykseen.
Sen sijaan, että kemistit kehittäisivät heuristisia malleja, uudet koneoppimismallit koulutetaan saatavilla olevan datan avulla.
Tämä on todettu merkittävästi toteutettavammaksi lähestymistavaksi~\cite{ColeyConnorW2018MLiC}.

Koneoppimismallien käyttö ja koulutus ei ole kuitenkaan täysin ongelmaton lähestymistapa.
Ongelmaan liittyvää dataa ei välttämättä ole saatavilla ja datan hankkiminen voi olla kallista~\cite{deAlmeidaA.Filipa2019Socd}.
Ei ole kehitetty julkista, kaikille avointa tietopankkia, joka sisältäisi tietoa kemiallisista reaktioista, vaan ainoastaan kaupallisia tietopankkeja on kehitetty, niin kuin Reaxys ja SciFinder~\cite{deAlmeidaA.Filipa2019Socd}.

\section{Lääkkeen retrosyntetisoinnin haastavuus}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{retrosynthesis.jpg}
    \caption{(a) esimerkki reaktiosäännöstä, (b) esimerkki mahdollisista reaktioista, kuinka voidaan luoda haluttu yhdiste (keskellä).
        Kuvaa on yksinkertaistettu ja se sisältää vain yksitoista mahdollista reaktiota, jotka tuottavat halutun yhdisteen.
        Värikoodaukset tarkoittavat: Keltainen --- haluttu yhdiste, Punainen --- saatavilla oleva yhdiste, Vihreä --- kirjallisuudesta tunnettu yhdiste, liila --- tuntematon yhdiste}
    {~\cite{ExpertKnowledgeRetorsynthesis}}
    \label{fig:retrosynthesis-example}
\end{figure}

Retrosyntetisoinnin tekee hankalaksi se, että tutkittaessa, kuinka haluttu yhdiste voidaan muodostaa, tulee käydä läpi satojatuhansia mahdollisia kemiallisia muunnoksia, joiden vaulla voidaan luoda haluttu yhdisteen~\cite{SeglerMarwinHS2018Pcsw}.
Kemialliseslla muunnoksella tai myöhemmin käytetyllä termillä muunnossääntö tarkoitetaan yleisesti kaikkia mahdollisia reaktioita tai reaktiotyyppejä, joita kemiassa tunnetaan.
Tämä ongelma toistuu rekursiivisesti, kun yhdiste pilkotaan yhdisteisiin, jotka keskenään reagoidessa muodostavat alkuperäisen yhdisteen.
Kuvassa~\ref{fig:retrosynthesis-example} näkyy, kuinka monella tavalla yksinkertainen yhdiste voidaan muodostaa.
Pienille ja yksinkertaisille yhdisteille tämä muunnostenavaruus on pienempi, mutta yhdisteen koon kasvaessa eri tapojen määrä muodostaa haluttu yhdiste kasvaa eksponentiaalisesti.

Tästä johtuen prosessia yleistäville koneoppimismalleille on suuri.

\section{Kehitettyjä apuvälineitä}

Seuraavissa luvuissa avataan kahden kehitetyn koneoppimismallin toimintaa.
Nämä mallit ovat toteutettu suorittaman retrosynteesiä, mutta niiden toimintaperiaate perustuu eri lähestymistapaan.

3N-MCTS -malli on kokonaisempi malli, koska se palauttaa retrosyntetisointipolun, joka kertoo, kuinka haluttu yhdiste voidaan syntetisoida laboratoriossa.
Se suodattaa jokaisessa retrosyntetisointivaiheessa kaikista mahdollisista muunnoksissta vain ne, jotka ovat toteutettavissa ja Monte carlo -puuhakualgoritmi etsii näiden suodatettujen muunnosten avulla retrosyntetisoinitpolun.

ICHO -malli taas puolestaan palauttaa parhaan muunnossäännön, jonka avulla haluttu yhdiste voidaan muodostaa.
ICHO -mallin toiminta on verrattavissa 3N-MCTS -mallissa käytetettyihin koneoppimismalleihin, jotka yhdessä suodattavat mahdollisista muunnoksista vain parhaimmat, joiden avulla yhdiste voidaan muodostaa.
ICHO -malli käyttää sekä samananlaista reaktiodataa kuin 3N-MCTS mutta se myös hyödyntää ammattikemistien luomia heuristisia sääntöjä.

\subsection{3N-MCTS -malli}

3N-MCTS on koneoppimismalli, jonka on kehittänyt Marwin et al.\ tutkimusryhmä.
Se etsii retrosynteesipolkuja yksinkertaisempiin ja saatavilla oleviin lähtöaineisiin~\cite{SeglerMarwinHS2018Pcsw}.
Kun retrosynteesipolku on varmennettu ja todettu toimivaksi, niin syötteenä annettu yhdiste on mahdollista syntetisoida laboratoriossa.

3N-MCTS -malli muodostuu kolmesta eri koneoppimismallista ja Monte Carlo -puuhakualgoritmista (\textbf{Monte Carlo Tree Search, MCTS}).
Neuroverkot on koulutettu avustamaan puuhakualgoritmia etenemään järkevimpään suuntaan, kun haku algoritmi etsii syntetisointipolkuja ja tarkistamaan, onko ehdotettu reaktio mahdollinen kyseiselle molekyylille.

Neuroverkot ovat hakupuun laajentumisen suuntaa ohjaava verkko (\textbf{Expansion policy network, EPN}), MCTS:än rollout toimintoa tukeva Rollout -verkko (\textbf{Rollout policy network, RPN}) ja verkko, joka tarkistaa, onko syntetisointi polku toteutettavissa (\textbf{In-scope filter network, IFN}).

Data, jolla neuroverkot koulutetaan, on peräisin Reaxys -tietokannasta.
Reaxyksen omistaa Elsevier kustantamo.
Reaxys -tietokannan sisältämä data koostuu muunnossäännöistä (\textbf{transformation rule}), jotka kertovat, mitkä lähtöaineet reagoivat keskenään, mikä reaktio on kysessä ja mikä on reaktion lopputuote.
Näitä sääntöjä käytetään mallien kouluttamiseen.
Tietokanta sisältää yli 12.4 miljoonaa sääntöä.
Mallien kouluttamiseen käytetyt säännöt sisältävät vain yksivaiheisia kemiallisia reaktioita ja reaktiossa on mukana vain yhdestä kolmeen lähtötuotetta.
Eri mallien kouluttamiseen käytetään eri kriteerein suodatettua dataa tietokannasta.
Kaikki koneoppimismallit koulutetaan käyttämällä ADAM -optimoijaa.
ADAM -optimoija on algoritmi, jota käytetään neuroverkon kaarien painojen optimoinnissa neuroverkon koulutusvaiheessa.
ADAM -optimoija perustuu stokastiseen gradientiin, mutta koska algoritmi on helppo toteuttaa ja se on laskennallisesti tehokas, niin se soveltuu neuroverkkojen optimointiin, jotka sisältävät paljon kaaria.
ADAM -optimoija hyödyntää AdaGrad:in ja RMSProp:in toiminnallisuutta~\cite{kingma2017adam}.

\subsubsection{3N-MCTS toimintamalli}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{3N-MCTS-fig.jpg}
    \caption{3N-MCTS:än toiminta periaate kuvattuna}
    {~\cite{SeglerMarwinHS2018Pcsw}}
    \label{fig:3n-mcts-model}
\end{figure}

3N-MCTS -mallin IFN ja EPN on kehitetty toimimaan yhdessä.
Tutkittaessa puun tilaa \(S_i\) jokainen molekyyli syötetään EPN:älle ja se tulostaa, mitkä säännöt voivat muodostaa annetun yhdisteen ja näin ollen myös mitkä lähtöaineet voivat muodostaa annetun yhdisteen.
Nämä säännöt syötetään IFN:älle, joka suodattaa valituista reaktioista toteutettavissa olevat vaihtoehdot.
3N-MCTS -mallin suoritusjärjestys on kuvattu kuvassa~\ref{fig:3n-mcts-model}.
Tätä toiminnallisuutta iteroidaan mallissa seuraavassa järjestyksessä.

(1) Ensimmäisessä vaiheessa algoritmi valitsee seuraavan lupaavimman tilan puusta kunnes puun lehti on saavutettu.
Jos lehdessä käydään ensimmäisen kerran valintavaiheen aikana, niin lehti arvostellaan simuloimalla hakualgoritmia \(d\) askelta eteenpäin samalla muodostaen synteesipolkua (rollout).
Jos lehdessä käydään useamman kuin yhden kerran valintavaiheen aikana, niin mahdolliset säännöt, jotka muodostavat lehden, tutkitaan ja lisätään lehden lapsiksi (expansion).

(2) Toisessa vaiheessa lupaavien tilojen lapset tutkitaan.
Tällöin etsitään lupaavimmat säännöt, jotka muodostavat kyseisessä tilassa olevan yhdisteen.

(3) Kolmannessa vaiheessa tarkistetaan lehden tila.
Jos lehti on `todistetusti toimiva', niin algoritmi palauttaa luvun suuremman kuin yksi, jolloin lehteä suositellaan käytettävän synteesipolussa.
Muussa tapauksessa lehdelle suoritetaan rollout, jolloin RPN antaa rekursiivisesti uusia sääntöjä niin kauan, kunnes lehti on pilkottu lähtöaineisiin tai kunnes suurin sallittu syvyys \(d\) on saavutettu.

(4) Viimeisessä vaiheessa lehtien arvot päivitetään.
Jos lähtöaineet löydetään rolloutin aikana, niin lehti saa palkonnoksi arvon 1.
Jos Kaikkia lähtöaineita ei löydetty, niin lehdelle annetaan osittainen palkinto.
Jos yhtään lähtöainetta ei löytynyt, niin lehti saa arvon -1.

Saattaa kuitenkin olla, että synteesipolkua ei voida luoda.
Joko synteesipolun tutkimiseen menee liian kauan aikaa tai synteesipolku sisältää liian monta vaihetta yhdisteen syntetisoimiseen.


\subsubsection{EPN -verkko}

\begin{figure}[!h]
    \centering
    \includegraphics[]{expansion-policy.jpg}
    \caption{Kuvassa expansion policy -neuroverkon rakenne.}
    {~\cite{SeglerMarwinHS2018Pcsw}}
    \label{fig:3n-mcts-epn}
\end{figure}

EPN muodostuu täysin kytketystä tasosta ja viidestä highway -tasosta.
Molemmissa tasoissa on käytetty aktivointifunktiona ELU -funktiota (\textbf{Exponential Linear Unit}).
Täysin kytketyssä tasossa suoritetaan dropout, jonka jälkeen vain 30 prosenttia ensimmäisen tason solmujen tuloksista otetaan huomioon seuraavalla tasolla.
Dropout -toiminolla tarkoitetaan, että vain tietty osa kaikista edellisen tason palauttamista arvoista huomioidaan~\cite{hinton2012improving}.
Dropout suoritetaan mallin koulutusvaiheessa ja pois jätettävät arvot valitaan sattumanvaraisesti.
Dropout -toiminnolla pyritään välttämään ylitulkintaa (overfitting).
Tämän jälkeen jokaisen highway -tason jälkeen suoritetaan dropout, jossa otetaan huomioon vain 10 prosenttia edellisen tason arvoista.
EPN -verkon viimeinen taso on softmax, joka palauttaa todennäköisyysjakauman.
Tämä jakauma kertoo kuinka todennäköisesti muunnossääntö \emph{a} muodostaa tuotteen \emph{m}.

EPN -verkon kouluttamiseen valittiin datasta vain reaktiokeskus.
Datasta suodatettiin pois sellaiset säännöt, jotka ilmenivät datassa alle kolme kertaa ennen vuotta 2015.
Lopullinen reaktiomäärä, jolla EPN koulutettiin, oli 301 671 reaktiota.

\subsubsection{RPN -verkko}

\begin{figure}[!h]
    \centering
    \includegraphics[]{rollout-policy.jpg}
    \caption{Kuvassa Rollout policy -neuroverkon rakenne.}
    {~\cite{SeglerMarwinHS2018Pcsw}}
    \label{fig:3n-mcts-rpn}
\end{figure}

% RPN on neuroverkko, jossa on yksi piilotettu kerros. RPN koulutettiin samalla tavalla kuin EPN.\@

RPN muodostuu yhdestä täysin kytketystä tasosta.
Samalla tavalla kuin EPN, RPN käyttää myös ELU -funktiota aktivointifunktiona.
RPN -tasossa suoritetaan dropout, jonka jälkeen vain 40 prosenttia kaikista ensimmäisen tason arvoista tulkitaan.
RPN -verkon viimeinen taso on myös softmax, joka palauttaa todennäköisyysjakauman.

RPN -verkon kouluttamiseen valittiin datasta vain reaktiossa muuttuneet atomit ja liitokset (reaktiokeskus) ja lähimmät vierekkäiset atomit.
Datasta suodatettiin pois sellaiset säännöt, jotka ilmaantuivat alle 50 kertaa ennen vuotta 2015.
Lopullinen reaktiomäärä, jolla RPN koulutettiin, oli 17 134 reaktiota.

\subsubsection{IFN -verkko}

\begin{figure}[!h]
    \centering
    \includegraphics[]{in-scope-filter.jpg}
    \caption{Kuvassa In scope filter -neuroverkon rakenne.}
    {~\cite{SeglerMarwinHS2018Pcsw}}
    \label{fig:3n-mcts-ifn}
\end{figure}

% IFN on neuroverkko, joka tarkistaa, onko EPN:än ja RPN:än valitsemat reaktiosäännöt toteutettavissa.

3N-MCTS:ässä IFN toimii binääriluokittelijana.
IFN kertoo, onko sille annettu yhdiste mahdollista muodostaa annetulla muunnossäännöllä.

IFN -neuroverkko muodostuu kahdesta haarasta.
Toinen haara saa syötteenä muodostettavan yhdisteen tunnisteen ja toinen haara saa muunnossäännön tunnisteen.

Haara, joka saa syöteenä yhdisteen tunnisteen, muodostuu yhdestä täysin kytketystä tasosta jonka jälkeen suoritetaan 30 prosentin dropout.
Tämän jälkeen data kulkee viiden highway -tason läpi.
Sekä täysin kytketty että highway -tasot käyttävät ELU -funktiota aktivointifunktiona.

Haara, joka saa syötteenään muunnossäännön tunnisteen, muodostuu vain yhdestä täysin kytketystä tasosta.
Tämä taso käyttää myös ELU -aktivointifuktiota.

Näiden haarojen jälkeen saaduista tuloksista lasketaan niiden kosinisamankaltaisuus.
Saatu tulos syötetään sitten sigmoid -funktiolle, jonka tulos kertoo, pystyykö kyseinen muunnosssäntö muodostamaan halutun yhdisteen.

IFN koulutetaan sekä onnistuneiden että epäonnistuiden sääntöjen avulla.
Koska epäonnistuneita sääntöjä ei tallenneta tietokantaan, niin kyseinen data generoidaan.
Data generoidaan siten, että jos reaktiossa \[A + B \rightarrow C\] lähtöaineet A ja B muodostavat reaktiossa lopputuotteen C, niin lopputuotteita D, E, F, jne.\@ ei muodostu.
IFN kouluttamista varten luotiin 100 miljoonaa epäonnistunutta reaktiota ja 10 miljoonaa epäonnistunutta reaktiota luotiin testaamista varten.

\subsubsection{3N-MCTS suorituskyky}

\begin{figure}[!h]
    \centering
    \includegraphics[width=8cm, height=6cm]{3N-MCTS-performance-fig.jpg}
    \caption{
        3N-MCTS:än suorituskyky verrattuna \(SMILES^{3/2}\) hyödyntävään BFS -menetelmään ja 3N-MCTS:än neuroverkkoja hyödyntävään BFS -menetelmään.
        Kuvaaja kertoo, kuinka monelle prosenttia annetuista yhdisteistä menetelmä kykenee löytämään retrosyntetisointipolun annaetusssa ajassa.
        Annetulla ajalla tarkoitetaan aikaa, jonka menetelmä voi korkeintaan käyttää yhden yhdisteen retrosyntetisointipolun löytämiseen.
    }
    {~\cite{SeglerMarwinHS2018Pcsw}}
    \label{fig:3n-mcts-performance}
\end{figure}

3N-MCTS -mallin suorituskykyä verrattiin BFS -menetelmään (Best-first search -method), joka käyttää heuristista käsinkoodattua \(SMILES^{3/2}\) -kustannefunktiota~\ref{fig:3n-mcts-performance}.
Tämä funktio antaa parhaimman tuloksen muunnossäännölle, joka jakaa halutun yhdisteen mahdollisimman hyvin yhtä suuriin lähtötuotteisiin.
Tästä menetelmästä luotiin myös versio, joka käyttää muokattua \(SMILES^{3/2}\) -kustannefunktiota.
Muokattu funktio käyttää 3N-MCTS:än expansion policy -neuroverkkoa ja in-scope filter -neuroverkkoa parhaimman muunnossäänön selvittämiseksi.

Mallit koulutettiin samoilla muunnossäännöillä ja testeissä käytettiin samaa aikaan perustuvaa jakoa.
Mallit koulutettiin muunnossäännöillä, jotka ilmenivät ennen vuotta 2015, ja malleja testatiin vuoden 2015 jälkeen ilmenneillä muunnossäänöillä.

Mallien tehtäväksi annettiin löytää halutulle yhdisteelle retrosyntetisointipolku annetussa ajassa.
Testaamiseen käytettiin 497 eri yhdistettä.

3N-MCTS suoriutui kahta muuta algoritmia paremmin jokaisessa eri aikakategoriassa.
3N-MCTS löysi viidessä sekunnissa 80 prosentille yhdisteistä retrosyntetisointipolun, kun taas muokattu \(SMILES^{3/2}\) -menetelmä löysi retrosyntetisointipolun vain 40 prosenttia yhdisteistä ja alkuperäinen ei löytänyt polkuja ollenkaan.
Kun aikaa kasvatettiin 60 sekunttiin per yhdiste, 3N-MCTS löysin 92 prosentille yhdisteistä polun, muokattu \(SMILES^{3/2}\) löysi 71 prosentille yhdisteistä ja alkuperäinen versio vain 4 prosentille yhdisteistä.

3N-MCTS:ää testattiin myös sokkotestillä 45 yliopistotason kemistille.
Testin tarkoituksena oli selvittää, suosivatko henkilöt ennemmin kirjallisuuteen perustuvaa retrosyntetisointipolkua vai 3N-MCTS:än antamaa polkua.
Sokkotestissä 57 prosenttia henkilöistä valitsi 3N-MCTS muodostaman polun ja loput valitsivat kirjallisuuteen perustuvan polun.

\subsection{ICHO -verkko}

On myös yleistä, että retrosynteesipolkuja suunnitelevat mallit hyödyntävät heurustiikka~\cite{ExpertKnowledgeRetorsynthesis}.
Badowski et al.\ ryhmä on kehittänyt koneoppimismallin, joka ehdottaa tietylle yhdisteelle parasta mahdollista muunnossääntöä, jonka avulla yhdiste voidaan muodostaa.
Kehitetty ICHIO -malli hyödyntää  neuroverkkoja ja ammattikemistien muodostamia heuristisia sääntöjä pisteyttäessään muunnossääntöjä.
ICHO-malli on verrattavissa 3N-MCTS -mallin EPN ja IFN verkkojen toimintaan.

ICHO:n (Instytut Chemii Organicznej) kouluttamiseen käyettiin dataa 1.4 miljoonasta reaktiosta ja niiden lopputuotteista.
Data saadaan julkaistuista artikkeleista ja patenteista.
Reaktiolta kuitenkin vaaditaan, että ainakin yksi reaktio per lopputuote löytyy myös Chematican expert-coded säännöstöstä.
Lisäksi datasta suodatettiin pois suojaryhmien säännöt.
Chematica on retrosyntetisointia suunnitteleva ohjelmisto ja tietokanta, joka sisältää dataa kemiallisista reaktioista.
Chematican omistaa nykyään Merck KGaA inc.\ ja sen nimi nykyään on Synthia.

ICHO:sta kehitettiin myös malli, jonka kouluttamisessa käytettiin lisäksi vektoreita, jotka sisälsivät dataa kemiallisesti intuitiivisistä reaktiopiirteistä, joita on käytetty aikaisemmissa tutkimuksissa.
Tätä mallia kutsutaan ICHO+ malliksi, ja sitä käytetään vertailemaan ICHO mallin suoriutumista.

Kehitetyssä ICHO mallissa on kaksi tärkeää asiaa.

(1) Se laskee reaktioiden ilmaantumistodennäköisyyttä uudelleen perustaen kuinka usein ne ilmaantuvat ammattilaisten käyttämissä reaktioissa.
Tämä laskenta tapahtuu mallin koulutusvaiheessa.
Käytännössä tämä tarkoittaa, että koulutusvaiheessa mallilla on tieto, kuinka monta kertaa tietty reaktiosääntö ilmeni datassa ja kuinka monta kertaa kyseistä reaktiota käytettiin luomaan jokin lopputuote.
Malli laskee näiden välisen suhteen, jolloin se pystyy määrittämään, kuinka usein kyseistä reaktiota kannattaa käyttää.
Jos esimerkiksi jokin reaktio on mainittu datassa kymmenen kertaa ja samassa datassa kyseistä reaktiota käytetään kymmenen kertaa luomaan jokin lopputuote, niin malli käyttää tätä reaktiota, koska se luokitellaan `Helpoksi ja varmaksi toteuttaa'.
Jos suhde taas on pieni, niin reaktio luokitellaan `vaikeaksi toteuttaa'.

(2) Toiseksi se kykenee antamaan suuremman kuin nollatodennäköisyyden reaktiolle, joka ei ilmaantunut koulutusvaiheessa.
Tämä sen takia, että mallille koulutetaan jatkuva funktio, joka antaa todennäköisyyden jokaiselle reaktiotyypille perustuen, kuinka reaktio muuttaa lopputuotteen lähtötuotteiksi.
Eli jos jokin reaktion sormenjälki tai heuristinen kuvaus on samankaltainen toisen reaktion kanssa, joka ilmenee koulutusdatassa, niin reaktiolle voidaan antaa todennäköisyys sen käytölle.

\begin{figure}[!h]
    \centering
    \includegraphics[width=8cm, height=8cm]{icho-neuralnetwork.png}
    \caption{ICHO -neuroverkon rakenne.}
    {~\cite{ExpertKnowledgeRetorsynthesis}}
    \label{fig:icho-neuralnetwork}
\end{figure}

ICHO -malli muodostuu neljästä kerroksesta, joista kolme kerrosta ovat täysin kytkettyjä neuroverkkoja ja viimeinen taso on sigmoid -taso~\ref{fig:icho-neuralnetwork}.
Samalla tavalla kuin 3N-MCTS mallissa, ICHO -malli käyttää myös ELU -aktivointifunktiota.
ICHO -malli käyttää Batch normaliztion -algoritmia koulutusvaiheessa.
Batch normalization -algoritmin idea on standardoida koulutusvaiheessa kerrokselle tuleva syöte, jolla verkon painoja muutetaan.

ICHO mallia vertailtiin aikasiemmin mainitun 3N-MCTS -mallin kanssa, jota kustsutaan artikkelissa SW mallina.
Kyseisestä SW mallista kehitettiin myös heuristista dataa hyödyntävä malli SW+.
Lisäksi luotiin SW malli, joka ei käy läpi kaikkia mahdollisia reaktioita, vaan valitsee säännöt niistä reaktioista, jotka eivät aiheuta konfliktia (selitys) ja jotka johtavat vain tiettyyn lopputuotteeseen.
Tätä mallia kutsutaan SW2 -malliksi ja tästä luodusta heuristisesta mallista käytetään nimeä SW2+.
Lisäksi vertailumalliksi luodaan täysin heuristinen malli \(SMALLER\), joka arvioi reaktioita sen mukaan, kuinka paljon ne rakenteellisesti yksinkertaistavat lopputuotetta.
Tämä malli suosii reaktioita, jotka pilkkovat molekyylin keskeltä, eli puolittavat sen.
Tämä on haluttu lähestymistapa retrosynteesiin, koska se minimoi syntetisointivaiheiden määrän.

\subsubsection{ICHO suorituskyky}

ICHO -mallia testataan eri tavalla kuin 3N-MCTS mallia, jossa mitataan, kuinka monelle yhdisteelle malli kykenee löytämään toimivan retrosyntetisointipolun tietyssä ajassa.
ICHO -mallia testataan siten, että jokaiselle mallille annetaan yhdiste, ja malli antaa tulosteena listan muunnossäännöistä, jotka on asetettu paremmuusjärjestykseen niille annetun pisteytyksen mukaan.
Muunnossäänön pisteytys kertoo, kuinka paljon malli suosittelee käytettävän kyseistä muunnossääntöä.
Näistä muunnossäännöistä laskettiin, kuinka suuri osa niistä pohjautuu johonkin aikaisempaan muunnossääntöön, joka on esiintynyt jossain kirjallisuudessa.
Mitä suurempi osa ehdotetuista muunnossäänöistä löytyy kirjallisuudesta, sitä paremmin malli toimii.

Kuvaajaan~\ref{fig:icho-performance} on piirretty vain eri mallien heuristiikkaa hyödyntävät versiot, koska ne pärjäsivät testeissä ei-heuristisia versioita paremmin.
Lisäksi kuvaajaan on piirretty \emph{SMALLER} malli vertailuksi.

Nähdään, että ICHO+ -malli pisteyttää kirjallisuuteen perustuvat muunnossäännöt paremmin kuin muut mallit, vaikkakin eroavaisuudet ovat vähäiset.

Kuvaajan~\ref{fig:icho-performance} kuvaajista b ja c nähdään, että pienelläkin koulutusaineistolla ICHO+ sijoittaa kirjallisuuden muunnossäännöt korkeammalle kuin muut mallit ja mitä enemmän koulutuaineistoa käytetään mallin kouluttamiseen sitä suurempi osa korkeimmin sijoitetuista muunnossäännöistä perustuvat kirjallisuuteen.
Mielenkiintoinen huomio, mikä kuvaajasta nähdään, että \emph{SMALLER} -malli sijoittaa kirjallisuuteen perustuvat säännöt pienemmällä koulutusaineistolla korkeammalle kuin suuremmalla aineistomäärällä.
SW2+ -malli taas toimii päinvastaisesti.
Mitä enemmän koulutusaineistoa se saa sitä korkeammalla se sijoittaa kirjallisuuteen perustuvat säännöt.

Kuvaajat d ja e eivät ole ristiriidassa kuvaajien a-c kanssa.
Kuvaajast d nähdään, että nopeasti koulutusaineiston kasvaessa tutkittvat muunnossäännöt siirtyvät nopeasti korkeille sijoille sw2+ -mallissa ja ICHO+ -malli sijoittaa ne korkealla jo pienellä data määrällä.
\emph{SMALLER} -malli sen sijaan sijoittaa tutkittavat muunnossäännöt koulutusaineiston kasvaessa huonommalle sijalle.
Kuvaaja e myös näyttää, että ICHO+ j SW2+ -mallien MRR -pisteet kasvavat koulutusaineiston kasvaessa, kun taas \emph{SMALLER} -mallin pisteytys laskee.

\begin{figure}[!h]
    \centering
    \includegraphics[width=10cm, height=10cm]{icho-performance-fig.jpg}
    \caption{
        ICHO -neuroverkon ja muiden testattujen koneoppimismallien suorituskyky kuvattuna.
        Kuvaajat a-c kertovat, kuinka suuri osa n-määrästä parhaiten pisteytettyjä muunnossääntöjä oli jostain kirjallisuudesta, esim.\ raportti.
        Esim, top 1 = 1 tarkoittaa, että malli antaa parhaimman pisteytyksen aina kirjallisuuteen perustuvalla muunnossäännölle.
        Kuvaaja d kertoo, mille sijalle kukin malli sijoittaa tietyn muunnossäännön.
        Tässä tapauksessa rank = 1 tarkoittaa, että malli sijoittaa tietyn muunnossäännön aina sijalle yksi.
        Kuvaaja e kertoo keskiarvon kirjallisuuteen perustuvien muunnossääntöjen käänteisestä sijoituksesta.
        Tämä tarkoittaa, että jos malli sijoittaa kaikkien kirjallisuuteen perustuvat muunnossäännöt ensimmäiseksi, niin MRR saa arvon yksi.
    }
    {~\cite{ExpertKnowledgeRetorsynthesis}}
    \label{fig:icho-performance}
\end{figure}

\chapter{Lääkkeiden kehitys tulevaisuudessa}

Vaikka koneoppimisen käyttökohteet ovat yleistyneet lääkekehityksessä, niin koneoppimisen lähestymistavoilla on edelleen potenttiaalia kehittyä~\cite{ButlerKeithT2018Mlfm}.

Yksi kehityksen kohteista on tehokkaampi datan tulkinta pienestä aineistomäärästä.
Paikoin kemian ja lääkekehityksen alalla on muihin koneoppimismallien käyttökohteisiin verrattaen vähän dataa saatavilla ja sitä on kallista tuottaa.
Tämä vaatii tutkijoilta enemmän työtä, jotta tieteellisistä julkaisuista saatava data saadaan koneiden hyödyntämään muotoon.
Toinen ratkaisu tähän on meta-oppimis (selitys) lähestymistapa.
Uudet lähestymistavat kuten Neuro Turing kone ja matkija oppiminen mahdollistavatkin oppimisen vähästä määrästä dataa ja Bayes luokittelija on suoriutunut lähes ihmistasoisesti käyttämällä One-shot oppismallia.

Toinen merkittävä edistysaskel on kemiallisten yhdisteiden ja reaktioiden tehokkaampi esitysmalli.
Tähän asti kemiaa on esitetty ihmisten ymmärtämässä muodossa, mutta tämä ei aina ole koneelle paras esitysmalli.
Koneoppimismallit käyttävät tietoa molekyyleistä ja atomeista ja koneoppimismallit ovat niin hyviä kuin nämä kuvaukset.
Hyvältä kuvaukselta vaaditaan, että sen avulla on yksinkertaista hankkia kohteen ominaisuudet ja sen tulee olla mahdollisimman pieni ulotteinen.
Uusia kuvausmalleja on kehitetty ja koska uudet mallit ovat näyttäneet, että ne ovat tehokkaita, niin uusien kuvauksien kehittäminen jatkuu edelleen.

Kemiallista koneoppimista edistävä asia on myös kvanttilaskennan hyödyntäminen.
Kvanttikoneiden suuri laskuteho pystyy vähentämään uusien mallien koulutusaikaa merkittävästi.

Koenoppimista voidaan mahdollisesti käyttää tulevaisuudessa uusien tieteellisten lakien löytämisessä.
Mutta vaikka eri koneoppimisesta kehitetyt mallit ovat ennalta arvattavia, niin ne eivät kuitenkaan ole aina tulkittavia.
Neuroverkko voi esimerkiksi oppia ideaalin kaasulain \((pV=nRT)\), mutta neuroverkon kaarien painojen muuttaminen ymmärrettäväksi säännöksi ei ole yksinkertainen tehtävä.
Voi olla, että koneoppimismalli pystyy huomaamaan datasta säännön, joka toistuu, mutta jos tutkijat eivät tiedä tai tunne kyseistä sääntöä, niin mallin tulkitseminen on lähes mahdotonta.

\chapter{Yhteenveto}

Tässä tekstissä käytiin läpi yleisiä asioita, mitä liittyy uusien lääkkeiden löytämiseen.
Lisäksi tekstissä käytiin läpi kolmen eri koneoppimismallin toimintaperiaatteet.
Nämä koneoppimismallit kertovat, kuinka koneoppimista voidaan hyödyntää uusien lääkkeiden löytämisessä ja syntetisoinnin suunnittelussa.
Koneoppimismalleista myös huomattiin, kuinka eri tavoilla koneoppimista voidaan hyödyntää ja kuinka monia eri tekniikoita voidaan käyttää lääkkeiden löytämisessä.

Vaikka tekstissä käytiin läpi koneoppimisen tekniikoita vain lääkkeiden löytämisen -ja syntetisoinnin kuvakulmasta, niin koneoppimista voidaan käyttää tehostamaan kaikkia lääkekehityksen prosessin vaiheita.


\cleardoublepage{}                          %fixes the position of bibliography in bookmarks
\phantomsection{}
\addcontentsline{toc}{chapter}{\bibname}  % This lines adds the bibliography to the ToC
\printbibliography{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\backmatter{}
% \begin{appendices}

%     \appendix{Sample Appendix\label{appendix:model}}
%     usually starts on its own page, with the name and number of the appendix at the top.
%     The appendices here are just models of the table of contents and the presentation. Each appendix
%     Each appendix is paginated separately.

%     In addition to complementing the main document, each appendix is also its own, independent entity.
%     This means that an appendix cannot be just an image or a piece of programming, but the appendix must explain its contents and meaning.

% \end{appendices}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
